{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>kabra_shreyansh_FinalProject</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Shreyansh Kabra\n",
    "<br>\n",
    "Github Username: kabrashrey\n",
    "<br>\n",
    "USC ID: 5690865072"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Transfer Learning for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) In this problem, we are trying to build a classifier that distinguishes images of nine types of waste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.2\n",
      "GPU devices found: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for GPU availability\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU devices found:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and configurations\n",
    "DATA_DIR = \"../data/RealWaste\"\n",
    "SPLIT_DIR = \"../data/RealWasteSplit\"\n",
    "TRAIN_SPLIT = 0.8\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Data Exploration and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) & (ii) Resizing, padding, train-test-split, and one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded and resized images saved to: ../data/RealWasteSplit\n"
     ]
    }
   ],
   "source": [
    "# Resize and pad images to a fixed size\n",
    "def pad_and_resize(image_path, target_size=IMG_SIZE):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image at {image_path} could not be read.\")\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "    scale = min(target_size[1] / w, target_size[0] / h)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    padded = np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8)\n",
    "    x_offset = (target_size[1] - new_w) // 2\n",
    "    y_offset = (target_size[0] - new_h) // 2\n",
    "    padded[y_offset:y_offset + new_h, x_offset:x_offset + new_w] = resized\n",
    "\n",
    "    return padded\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "if os.path.exists(SPLIT_DIR):\n",
    "    shutil.rmtree(SPLIT_DIR)\n",
    "\n",
    "for class_name in sorted(os.listdir(DATA_DIR)):\n",
    "    class_dir = os.path.join(DATA_DIR, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "\n",
    "    all_images = sorted(os.listdir(class_dir))\n",
    "    train_size = int(len(all_images) * TRAIN_SPLIT)\n",
    "\n",
    "    train_imgs = all_images[:train_size]\n",
    "    test_imgs = all_images[train_size:]\n",
    "\n",
    "    for split, split_imgs in zip(['train', 'test'], [train_imgs, test_imgs]):\n",
    "        split_dir = os.path.join(SPLIT_DIR, split, class_name)\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "        \n",
    "        for img in split_imgs:\n",
    "            src = os.path.join(class_dir, img)\n",
    "            dst = os.path.join(split_dir, img)\n",
    "            try:\n",
    "                output_img = pad_and_resize(src, IMG_SIZE)\n",
    "                cv2.imwrite(dst, output_img)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {img}: {e}\")\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "print(\"Padded and resized images saved to:\", SPLIT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3798 files belonging to 9 classes.\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "input: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "_EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "components_0: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "TensorSliceDataset: (TensorSliceDataset): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "input: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "_EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "components_0: (_DeviceArg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "TensorSliceDataset: (TensorSliceDataset): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "input__datasets_0: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "input__datasets_1: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "ZipDataset: (ZipDataset): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "input: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "_EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "x: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "y: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Equal: (Equal): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "z_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Equal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Equal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "x: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "y: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "LogicalAnd: (LogicalAnd): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "z_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalAnd in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "condition: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "t: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "e: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "SelectV2: (SelectV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op SelectV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "DummySeedGenerator: (DummySeedGenerator): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DummySeedGenerator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "input__dataset: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "buffer__size: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "seed: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "seed2: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "seed__generator: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "ShuffleDatasetV3: (ShuffleDatasetV3): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ShuffleDatasetV3 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "input__dataset: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "num__parallel__calls: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "ParallelMapDatasetV2: (ParallelMapDatasetV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "input: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "_EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "input__dataset: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "batch__size: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "drop__remainder: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "BatchDatasetV2: (BatchDatasetV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op BatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "input__dataset: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "buffer__size: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "PrefetchDataset: (PrefetchDataset): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Found 954 files belonging to 9 classes.\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "components_0: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "TensorSliceDataset: (TensorSliceDataset): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "components_0: (_DeviceArg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "TensorSliceDataset: (TensorSliceDataset): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "input__datasets_0: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "input__datasets_1: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "ZipDataset: (ZipDataset): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Equal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Equal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LogicalAnd in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op SelectV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DummySeedGenerator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "input__dataset: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "buffer__size: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "seed: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "seed2: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "seed__generator: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "ShuffleDatasetV3: (ShuffleDatasetV3): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ShuffleDatasetV3 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "input__dataset: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "num__parallel__calls: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "ParallelMapDatasetV2: (ParallelMapDatasetV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "input__dataset: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "batch__size: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "drop__remainder: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "BatchDatasetV2: (BatchDatasetV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op BatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "input__dataset: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "buffer__size: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "PrefetchDataset: (PrefetchDataset): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "input__dataset: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "MapDataset: (MapDataset): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "input__dataset: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "buffer__size: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "PrefetchDataset: (PrefetchDataset): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "input__dataset: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "MapDataset: (MapDataset): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "input__dataset: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "buffer__size: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "PrefetchDataset: (PrefetchDataset): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "handle_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding\n",
    "raw_train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(SPLIT_DIR, 'train'),\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    "    label_mode='int'\n",
    "    )\n",
    "\n",
    "raw_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(SPLIT_DIR, 'test'),\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    "    label_mode='int'\n",
    "    )\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "NUM_CLASSES = len(class_names)\n",
    "\n",
    "def one_hot_encode(image, label):\n",
    "    \"\"\"Convert integer labels to one-hot encoded format.\"\"\"\n",
    "    return image, tf.one_hot(label, depth=NUM_CLASSES)\n",
    "\n",
    "train_ds = raw_train_ds.map(one_hot_encode).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = raw_test_ds.map(one_hot_encode).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRaw labels (integer class indices): \\n[6 3 3 8 6 7 7 7 4 7 2 6 4 1 4 7 2 6 0 5 6 7 7 6 3 2 3 4 5 3 3 5]\\n\\nOne-hot encoded labels:\\n[[0. 1. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 0. 0. 1.]\\n [0. 0. 0. 0. 1. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 1. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 1. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 1. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 1. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 0. 1. 0.]\\n [0. 0. 0. 0. 0. 0. 1. 0. 0.]\\n [0. 0. 1. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 1. 0. 0. 0. 0. 0.]\\n [0. 1. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 0. 0. 1.]\\n [0. 0. 0. 0. 0. 0. 0. 0. 1.]\\n [0. 0. 1. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 1. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 1. 0. 0. 0. 0. 0.]\\n [0. 1. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 1. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 0. 0. 1.]\\n [0. 0. 0. 1. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 1. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 1. 0. 0.]\\n [1. 0. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 1. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 0. 0. 1.]\\n [0. 0. 0. 0. 1. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 0. 1. 0.]\\n [1. 0. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 1. 0. 0. 0. 0.]\\n [0. 0. 1. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 1. 0. 0.]]\\n \\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Difference between raw and one-hot encoded labels\n",
    "# for images, labels in raw_train_ds.take(1):\n",
    "#     print(\"Raw labels (integer class indices):\", labels.numpy())\n",
    "\n",
    "# for images, labels in train_ds.take(1):\n",
    "#     print(\"One-hot encoded labels:\")\n",
    "#     print(labels.numpy())\n",
    "\n",
    "\"\"\"\n",
    "Raw labels (integer class indices): \n",
    "[6 3 3 8 6 7 7 7 4 7 2 6 4 1 4 7 2 6 0 5 6 7 7 6 3 2 3 4 5 3 3 5]\n",
    "\n",
    "One-hot encoded labels:\n",
    "[[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
    " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
    " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
    " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
    " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
    " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
    " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
    " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
    " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
    " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
    " \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://builtin.com/data-science/transfer-learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
